{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/wkentaro/pytorch-for-numpy-users/blob/master/README.md\n",
    "\n",
    "#https://stackoverflow.com/questions/51858067/parsing-csv-into-pytorch-tensors\n",
    "\n",
    "#https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/\n",
    "\n",
    "#https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers\n",
    "\n",
    "#https://medium.com/biaslyai/learn-pytorch-basics-6d433f186b7a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as pt\n",
    "# import tensorflow as tf\n",
    "# import tensorflow.keras as ktf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "#1. numpy\n",
    "np_a = np.arange(1,10)\n",
    "print(np_a)\n",
    "\n",
    "#torch\n",
    "\n",
    "\n",
    "#2. How to create a 1D tensor in torch ?\n",
    "pt_a = pt.arange(1,10)\n",
    "print(pt_a)\n",
    "\n",
    "\n",
    "#tensorflow\n",
    "#sess = tf.Session()\n",
    "#tf_a = tf.range(1,10)\n",
    "#sess.run(tf_a)\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    print(\":::::::tf\",tf_a.eval())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. How to create a boolean tensor in torch ?\n",
    "\n",
    "# error :: Canâ€™t convert np.ndarray of type numpy.bool_\n",
    "\n",
    "bool_array = np.ones((3,4),dtype=np.uint8)\n",
    "pt.from_numpy(bool_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. How to extract items that satisfy a given condition from 1D tensor in torch ?\n",
    "\n",
    "arr = pt.tensor([1,2,3,4,5,6,7,8,9])\n",
    "arr[arr % 2 == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  2, -1,  4, -1,  6, -1,  8, -1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. How to replace items that satisfy a condition with another value in tensor ?\n",
    "\n",
    "\n",
    "arr = pt.tensor([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "arr[arr % 2 == 1] = -1\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  2, -1,  4, -1,  6, -1,  8, -1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. How to replace items that satisfy a condition without affecting the original tensor in torch ?\n",
    "\n",
    "arr = pt.tensor([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "replace_arr = pt.tensor([-1])\n",
    "\n",
    "output = pt.where(arr % 2 == 1, replace_arr, arr)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. How to reshape an tensor in torch ?\n",
    "\n",
    "arr = pt.arange(0,9)\n",
    "arr.reshape(3,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenate:\n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]])\n",
      "vstack:\n",
      " tensor([[[0, 1, 2, 3, 4],\n",
      "         [5, 6, 7, 8, 9]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1]]])\n"
     ]
    }
   ],
   "source": [
    "#8. how to stack tensor vertically in torch ?\n",
    "\n",
    "a = pt.arange(10).reshape(2, -1)\n",
    "b = pt.tensor(1).repeat(10).reshape(2,-1)\n",
    "\n",
    "\n",
    "print(\"concatenate:\\n\",pt.cat([a,b], 0))\n",
    "print(\"vstack:\\n\",pt.stack([a,b], 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenate:\n",
      " tensor([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],\n",
      "        [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]])\n",
      "hstack:\n",
      " tensor([[[0, 1, 2, 3, 4],\n",
      "         [1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[5, 6, 7, 8, 9],\n",
      "         [1, 1, 1, 1, 1]]])\n"
     ]
    }
   ],
   "source": [
    "#9. How to stack two arrays horizontally in torch ?\n",
    "\n",
    "a = pt.arange(10).reshape(2, -1)\n",
    "b = pt.tensor(1).repeat(10).reshape(2,-1)\n",
    "\n",
    "print(\"concatenate:\\n\",pt.cat([a,b], 1))\n",
    "print(\"hstack:\\n\",pt.stack([a,b], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10. How to generate custom sequences in torch without hardcoding in torch ?\n",
    "\n",
    "t = pt.tensor([1,2,3])\n",
    "\n",
    "t1=t.repeat(3)\n",
    "t2=t.repeat(3).reshape(3,-1).transpose(1,0).reshape(-1)\n",
    "\n",
    "pt.cat([t1,t2],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices::: tensor([1, 1, 1, 1, 0], dtype=torch.uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11. How to remove from one array those items that exist in another in torch ?\n",
    "\n",
    "t1 = pt.tensor([1,2,3,4,5])\n",
    "t2 = pt.tensor([5,6,7,8,9])\n",
    "\n",
    "indices = pt.ones_like(t1, dtype = pt.uint8)\n",
    "for elem in t2:\n",
    "    indices = indices & (t1 != elem)\n",
    "    \n",
    "print(\"indices:::\",indices)\n",
    "intersection = t1[indices]  \n",
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12. How to get the common items between two tensor torch?\n",
    "\n",
    "a = pt.tensor([1,2,3,2,3,4,3,4,5,6])\n",
    "b = pt.tensor([7,2,3,2,7,4,9,4,9,8])\n",
    "\n",
    "equal_data = pt.eq(a, b)\n",
    "pt.unique(pt.cat([a[equal_data],b[equal_data]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5],\n",
       "        [7]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13. How to get the positions where elements of two tensor match pytorch\n",
    "\n",
    "a = pt.tensor([1,2,3,2,3,4,3,4,5,6])\n",
    "b = pt.tensor([7,2,10,2,7,4,9,4,9,8])\n",
    "\n",
    "pt.nonzero(pt.eq(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14. How to extract all numbers between a given range from a pytorch tensor?\n",
    "\n",
    "a = pt.tensor([11,12,13,14,15,16])\n",
    "mask = (a >=11) & (a <= 15)\n",
    "a[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 9, 8, 9, 7, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15. How to pick max value from two tensor in pytorch?\n",
    "\n",
    "a = pt.tensor([5, 7, 9, 8, 6, 4, 5])\n",
    "b = pt.tensor([6, 3, 4, 8, 9, 7, 1])\n",
    "\n",
    "pt.max(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2],\n",
       "        [3, 5, 4],\n",
       "        [7, 9, 8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#16. How to swap two columns in a 2d tensor in pytorch?\n",
    "\n",
    "a = pt.tensor([[1,2,3],[3,4,5],[7,8,9]])\n",
    "\n",
    "i1 = pt.index_select(a, 1, pt.LongTensor([0,2]))\n",
    "i2 = pt.index_select(a, 1, pt.LongTensor([1]))\n",
    "\n",
    "pt.cat((i1,i2), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#17. How to swap two rows in a 2d tensor in pytorch?\n",
    "\n",
    "a = pt.tensor([[1,2,3],[3,4,5],[7,8,9]])\n",
    "\n",
    "i1 = pt.index_select(a, 0, pt.LongTensor([0,2]))\n",
    "i2 = pt.index_select(a, 0, pt.LongTensor([1]))\n",
    "print(i2)\n",
    "#pt.cat((i1,i2), dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before :: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "After :: tensor([[7, 8, 9],\n",
      "        [4, 5, 6],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "#18. How to reverse the rows of a 2d tensor in pytorch ?\n",
    "\n",
    "aa = pt.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "idx = [i for i in range(aa.size(0)-1, -1, -1)]\n",
    "idx = pt.LongTensor(idx)\n",
    "inverted_tensor = pt.index_select(aa,0,idx)\n",
    "print(\"Before ::\",aa)\n",
    "print(\"After ::\",inverted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before :: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "After :: tensor([[3, 2, 1],\n",
      "        [6, 5, 4],\n",
      "        [9, 8, 7]])\n"
     ]
    }
   ],
   "source": [
    "#19. How to reverse the columns of a 2d tensor in pytorch ?\n",
    "\n",
    "aa = pt.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "idx = [i for i in range(aa.size(0)-1, -1, -1)]\n",
    "idx = pt.LongTensor(idx)\n",
    "inverted_tensor = pt.index_select(aa,1,idx)\n",
    "print(\"Before ::\",aa)\n",
    "print(\"After ::\",inverted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.2637, 9.7855, 6.2776],\n",
       "        [7.5562, 5.2533, 7.3286]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20  How to create a 2D tensor containing random floats between 5 and 10?\n",
    "\n",
    "pt.empty(2,3).uniform_(5,10).type(pt.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.752, 0.085, 0.889],\n",
       "        [0.259, 0.107, 0.156],\n",
       "        [0.990, 0.867, 0.998]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#21 How to print only 3 decimal places in pyorch tensor?\n",
    "\n",
    "arr = pt.rand((3,3))\n",
    "pt.set_printoptions(precision=3)\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  3,  4,  ..., 47, 48, 49])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 22 How to limit the number of items printed in output of torch tensor\n",
    "\n",
    "arr = pt.arange(2,50)\n",
    "pt.set_printoptions(threshold=5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "        38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#23 How to print the full pytorch tensor without truncating\n",
    "#https://discuss.pytorch.org/t/print-a-verbose-version-of-a-tensor/11201\n",
    "\n",
    "arr = pt.arange(2,50)\n",
    "pt.set_printoptions(profile=\"default\")\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "x:::: tensor([1.], requires_grad=True)\n",
      "tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "#24 Autograd\n",
    "#https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb\n",
    "#https://medium.com/@tomgrek/building-your-first-neural-net-from-scratch-with-pytorch-56b0e9c84d54\n",
    "\n",
    "import torch \n",
    "x = torch.ones(1, requires_grad=True)\n",
    "print(x.grad)    # returns None\n",
    "\n",
    "\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "print(\"x::::\",x)\n",
    "y = x + 2\n",
    "z = y * y * 2\n",
    "z.backward()     # automatically calculates the gradient\n",
    "print(x.grad)    # âˆ‚z/âˆ‚x = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x::::: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "z::::: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = pt.zeros(3, 2)\n",
    "x = z.view(2, 3)\n",
    "z.fill_(1)\n",
    "print(\"x:::::\",x)\n",
    "print(\"z:::::\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueeze 0:: tensor([[1, 2, 3, 4]])\n",
      "unsqueeze 1:: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "#unsqueeze pytorch\n",
    "#numpy-newaxis-work\n",
    "\n",
    "#https://stackoverflow.com/questions/29241056/how-does-numpy-newaxis-work-and-when-to-use-it\n",
    "\n",
    "\n",
    "x = pt.tensor([1, 2, 3, 4])\n",
    "\n",
    "x1 = torch.unsqueeze(x, 0)\n",
    "x2 = torch.unsqueeze(x, 1)\n",
    "print(\"unsqueeze 0::\",x1)\n",
    "print(\"unsqueeze 1::\",x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.squeeze(x1, 0)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:::: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "a1:::: tensor([[1, 3],\n",
      "        [2, 4]])\n",
      "a2:::: tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/51143206/difference-between-tensor-permute-and-tensor-view-in-pytorch\n",
    "\n",
    "a = torch.tensor([[1,2],[3,4]])\n",
    "print(\"a::::\",a)\n",
    "\n",
    "a1 = a.permute(1, 0)\n",
    "print(\"a1::::\",a1)\n",
    "\n",
    "a2 = a.permute(0, 1)\n",
    "print(\"a2::::\",a2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of tensor::: 12\n",
      "1D tensor torch.Size([12])\n",
      "2D tensor torch.Size([12, 1])\n",
      "3D tensor torch.Size([12, 1, 1])\n",
      "3D reshape tensor torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#unsqueeze pytorch\n",
    "#numpy-newaxis-work\n",
    "\n",
    "#https://stackoverflow.com/questions/29241056/how-does-numpy-newaxis-work-and-when-to-use-it\n",
    "\n",
    "\n",
    "# how to convert 1D tensor to 2D tensor\n",
    "\n",
    "#x_train  = torch.linspace(-1, 1, 101)    # 1D tensor\n",
    "\n",
    "x_train  = torch.tensor([0,1,2,3,4,6,7,8,9,10,11,12])    # 1D tensor\n",
    "\n",
    "print(\"len of tensor:::\",len(x_train))\n",
    "\n",
    "print(\"1D tensor\",x_train.size())\n",
    "\n",
    "#x_train = x_train.view(12, 1) # convert to 2D tensor\n",
    "x_train = x_train.unsqueeze(1) # convert to 2D tensor\n",
    "\n",
    "print(\"2D tensor\", x_train.size())\n",
    "\n",
    "#x_train = x_train.view(11, 1) # convert to 3D tensor\n",
    "x_train3D_unsqueeze = x_train.unsqueeze(-1) # convert to 3D tensor\n",
    "print(\"3D tensor\", x_train3D_unsqueeze.size())\n",
    "\n",
    "x_train3D_reshape =  x_train.reshape(2,2,3)\n",
    "print(\"3D reshape tensor\", x_train3D_reshape.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://discuss.pytorch.org/t/torch-repeat-and-torch-expand-which-to-use/27969\n",
    "\n",
    "a = torch.Tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "a.unsqueeze_(-1)\n",
    "a = a.expand(3,3,11)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::: tensor([[2.7224e+20, 7.7782e+31, 4.7429e+30],\n",
      "        [1.3818e+31, 1.7225e+22, 1.4602e-19]])\n"
     ]
    }
   ],
   "source": [
    "#create constructors with empty_like tensor\n",
    "\n",
    "x = torch.zeros(2,3)\n",
    "empty_like = torch.empty_like(x)\n",
    "print(\"::::\",empty_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -5.,   0.,   5.,  10.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create numerical ranges with linspace return 1-D tensor\n",
    "\n",
    "x_linespace = torch.linspace(-10, 10, steps=5)\n",
    "x_linespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 12, 12],\n",
       "        [24, 24, 24]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear algebra pytorch.mm\n",
    "\n",
    "aa = torch.tensor([[1, 1, 1],[2, 2, 2]])\n",
    "\n",
    "bb = torch.tensor([[3, 3, 3],[4, 4, 4],[5, 5, 5]])\n",
    "\n",
    "cc = torch.tensor([[3, 3, 3],[4, 4, 4]])\n",
    "\n",
    "\n",
    "#not working with \"cc\" tensor bcoz of ,\n",
    "#torch.mm(aa,cc) bcoz of mat1 is a (nÃ—m) tensor, mat2 is a (mÃ—p) tensor, out will be a (nÃ—p) tensor.\n",
    "\n",
    "#working Just calculation:::: 1*3+1*4+1*5\n",
    "# \n",
    "\n",
    "torch.mm(aa,bb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::: tensor([4, 6, 7])\n",
      ":::: tensor([3, 4])\n",
      "::::: tensor([3])\n"
     ]
    }
   ],
   "source": [
    "#get diagonal from tensor\n",
    "\n",
    "bb = torch.tensor([[4, 3, 3],[4, 6, 4],[5, 5, 7]])\n",
    "print(\"::::\",torch.diag(bb,0))\n",
    "print(\"::::\",torch.diag(bb,1))\n",
    "print(\":::::\",torch.diag(bb,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 0, 0],\n",
      "        [4, 6, 0],\n",
      "        [5, 5, 7]])\n",
      "tensor([[4, 3, 0],\n",
      "        [4, 6, 4],\n",
      "        [5, 5, 7]])\n"
     ]
    }
   ],
   "source": [
    "#get lower triangular part of the tensor \n",
    "\n",
    "bb = torch.tensor([[4, 3, 3],[4, 6, 4],[5, 5, 7]])\n",
    "\n",
    "print(torch.tril(bb,0))\n",
    "print(torch.tril(bb,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3, 3],\n",
      "        [0, 6, 4],\n",
      "        [0, 0, 7]])\n",
      "tensor([[0, 3, 3],\n",
      "        [0, 0, 4],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#get upper triangular part of the tensor \n",
    "\n",
    "bb = torch.tensor([[4, 3, 3],[4, 6, 4],[5, 5, 7]])\n",
    "\n",
    "print(torch.triu(bb,0))\n",
    "print(torch.triu(bb,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype:::: torch.int64\n",
      "stride::::: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# calculate stride of the tensor (memory)\n",
    "#https://www.jessicayung.com/numpy-arrays-memory-and-strides/\n",
    "\n",
    "bb = torch.tensor([[4, 3, 3],[4, 6, 4],[5, 5, 7]])\n",
    "\n",
    "print(\"dtype::::\",bb.dtype)\n",
    "print(\"stride:::::\",bb.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 5, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select indexing based on tensor indices \n",
    "\n",
    "src = torch.tensor([[4, 3, 5],[6, 7, 8]])\n",
    "\n",
    "torch.take(src, torch.tensor([0, 1, 2, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      ":::: tensor([[              1,               2,               3],\n",
      "        [              4,               5,               6],\n",
      "        [140114718097420,     64424509440,               0]])\n"
     ]
    }
   ],
   "source": [
    "# resize_  Resizes self tensor to the specified size. \n",
    "#If the number of elements is larger than the current storage size, then the underlying storage is resized to fit the new number of elements\n",
    "\n",
    "\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(\":::\",x.resize_(2, 2))\n",
    "print(\"::::\",x.resize_(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: torch.return_types.sort(\n",
      "values=tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 7]]),\n",
      "indices=tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]]))\n",
      "::::dim 2\n",
      "::: torch.return_types.sort(\n",
      "values=tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 7]]),\n",
      "indices=tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "#sort tensor \n",
    "\n",
    "x = torch.tensor([[2,1], [4,3], [7,5]])\n",
    "print(\":::\",x.sort())\n",
    "print(\"::::dim\",x.dim())\n",
    "print(\":::\",torch.sort(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::: tensor([[8, 9],\n",
      "        [7, 5],\n",
      "        [4, 3],\n",
      "        [2, 1]])\n",
      ":::: tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 7],\n",
      "        [9, 8]])\n",
      ":::: tensor([[9, 8],\n",
      "        [5, 7],\n",
      "        [3, 4],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "#flip tensor\n",
    "\n",
    "x = torch.tensor([[2,1], [4,3], [7,5],[8,9]])\n",
    "print(\"::::\",x.flip(0))\n",
    "print(\"::::\",x.flip(1))\n",
    "print(\"::::\",x.flip([0,1]))\n",
    "#print(\"::::\",x.flip([1,0])) output are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::: tensor(15.)\n"
     ]
    }
   ],
   "source": [
    "# trace tensor Returns the sum of the elements of the diagonal of the input matrix.\n",
    "\n",
    "a = torch.arange(1.,10.).view(3,3)\n",
    "\n",
    "print(\"::::\",torch.trace(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  3,  6, 10, 15, 21, 28, 36, 45])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cumsum in tensor \n",
    "\n",
    "a = torch.arange(1,10)\n",
    "\n",
    "torch.cumsum(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the indices of all elements in the input tensor.\n",
    "\n",
    "a = torch.tensor([[1,2,3],[4,5,6],[-1,0,1]])\n",
    "torch.argmax(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([15, 32])\n"
     ]
    }
   ],
   "source": [
    "# Performs a matrix-vector product of the matrix.\n",
    "\n",
    "mat = torch.tensor([[2,2,3],[4,5,6]])\n",
    "print(mat.size())\n",
    "vec = torch.tensor([1,2,3])\n",
    "\n",
    "\"\"\"\n",
    "2*1 + 2*2 + 3*3  \n",
    "1*4 + 2*5 + 3*6\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ans = torch.mv(mat, vec)\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#get items from tensor\n",
    "\n",
    "a = torch.Tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# replace an element at position 0, 0\n",
    "a[0][0] = 5\n",
    "\n",
    "# access an element at position 1, 0\n",
    "print(a[1][0])\n",
    "print(a[1][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., -2.],\n",
       "        [ 2.,  2.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor requires_grad\n",
    "x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n",
    "out = x.pow(2).sum()\n",
    "\n",
    "out.backward()\n",
    "x.grad\n",
    "x.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 2],\n",
       "         [1, 1]]), tensor([[3, 4],\n",
       "         [8, 9]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A tensor can be split between multiple chunks\n",
    "\n",
    "x = torch.tensor([[2, 2], [1, 1],[3, 4],[8, 9]])\n",
    "\n",
    "torch.chunk(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::x tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12],\n",
      "        [13, 14, 15]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  4,  7, 10, 13]),\n",
       " tensor([ 2,  5,  8, 11, 14]),\n",
       " tensor([ 3,  6,  9, 12, 15]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unbind function removes a dimension from a tensor\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15]])\n",
    "\n",
    "print( \"::::::x\", x)\n",
    "\n",
    "torch.unbind(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bernoulli distribution \n",
    "\n",
    "x = torch.Tensor(4,4).uniform_(0,1)\n",
    "torch.bernoulli(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0382,  2.8145,  2.6497,  4.4358,  4.1428,  6.1307,  7.1371,  7.6426,\n",
      "         8.4751, 11.1289])\n",
      "tensor([ 0.6191,  1.0408,  2.4983,  4.8560,  4.1512,  6.5729,  6.9811,  8.1268,\n",
      "         8.8706, 10.1291])\n"
     ]
    }
   ],
   "source": [
    "#To compute standard  deviation  and mean\n",
    "\n",
    "print(torch.normal(mean=torch.arange(1.,11.)))\n",
    "#print(torch.normal(std=torch.arange(1,0,-0.1)))\n",
    "\n",
    "print(torch.normal(mean=torch.arange(1.,11.), std=torch.arange(1,0,-0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad 11.0 21.0 tensor(-220.)\n",
      "grad 22.0 14.0 tensor(2481.6001)\n",
      "grad 33.0 64.0 tensor(-51303.6484)\n",
      "::::: 0 tensor(604238.8125)\n",
      "grad 11.0 21.0 tensor(118461.7578)\n",
      "grad 22.0 14.0 tensor(-671630.6875)\n",
      "grad 33.0 64.0 tensor(13114108.)\n",
      "::::: 1 tensor(3.9481e+10)\n",
      "grad 11.0 21.0 tensor(-30279010.)\n",
      "grad 22.0 14.0 tensor(1.7199e+08)\n",
      "grad 33.0 64.0 tensor(-3.3589e+09)\n",
      "::::: 2 tensor(2.5900e+15)\n",
      "grad 11.0 21.0 tensor(7.7553e+09)\n",
      "grad 22.0 14.0 tensor(-4.4050e+10)\n",
      "grad 33.0 64.0 tensor(8.6030e+11)\n",
      "::::: 3 tensor(1.6991e+20)\n",
      "grad 11.0 21.0 tensor(-1.9863e+12)\n",
      "grad 22.0 14.0 tensor(1.1282e+13)\n",
      "grad 33.0 64.0 tensor(-2.2034e+14)\n",
      "::::: 4 tensor(1.1146e+25)\n",
      "grad 11.0 21.0 tensor(5.0875e+14)\n",
      "grad 22.0 14.0 tensor(-2.8897e+15)\n",
      "grad 33.0 64.0 tensor(5.6436e+16)\n",
      "::::: 5 tensor(7.3118e+29)\n",
      "grad 11.0 21.0 tensor(-1.3030e+17)\n",
      "grad 22.0 14.0 tensor(7.4013e+17)\n",
      "grad 33.0 64.0 tensor(-1.4455e+19)\n",
      "::::: 6 tensor(4.7966e+34)\n",
      "grad 11.0 21.0 tensor(3.3374e+19)\n",
      "grad 22.0 14.0 tensor(-1.8957e+20)\n",
      "grad 33.0 64.0 tensor(3.7022e+21)\n",
      "::::: 7 tensor(inf)\n",
      "grad 11.0 21.0 tensor(-8.5480e+21)\n",
      "grad 22.0 14.0 tensor(4.8553e+22)\n",
      "grad 33.0 64.0 tensor(-9.4824e+23)\n",
      "::::: 8 tensor(inf)\n",
      "grad 11.0 21.0 tensor(2.1894e+24)\n",
      "grad 22.0 14.0 tensor(-1.2436e+25)\n",
      "grad 33.0 64.0 tensor(2.4287e+26)\n",
      "::::: 9 tensor(inf)\n"
     ]
    }
   ],
   "source": [
    "# To compute the gradient of the two data lists requires computations of a loss function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_data = [11.0, 22.0, 33.0]\n",
    "y_data = [21.0, 14.0, 64.0]\n",
    "\n",
    "w = Variable(torch.tensor([1.0]),requires_grad=True) # any random variable\n",
    "\n",
    "#print(\"predict (before training)\", 4, forward(4).data[0])\n",
    "\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    #error get like (MSE)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    for x_val , y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(\"grad\", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        w.grad.data.zero_()\n",
    "\n",
    "    print(\":::::\",epoch, l.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8323, 0.1120, 0.8695, 0.7284],\n",
       "        [0.7497, 0.9765, 0.8989, 1.0014],\n",
       "        [0.8027, 0.2768, 0.9374, 0.6354],\n",
       "        [0.8371, 0.2463, 0.5359, 1.2751]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define matrix \n",
    "\n",
    "mat1 = torch.FloatTensor(4,4).uniform_(0,1)\n",
    "mat2 = torch.FloatTensor(5,4).uniform_(0,1)\n",
    "\n",
    "#define vector\n",
    "vac1 = torch.FloatTensor(4).uniform_(0,1)\n",
    "\n",
    "\n",
    "#scalar addition\n",
    "\n",
    "mat1 + 10.5\n",
    "\n",
    "#scalar subtraction\n",
    "\n",
    "mat2 - 0.50\n",
    "\n",
    "\n",
    "# vecotor and matrix addition\n",
    "\n",
    "c= mat1 + vac1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
      "        48.4000])\n",
      "tensor(1656.5790)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([40.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n",
    "\n",
    "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0])\n",
    "\n",
    "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4])\n",
    "\n",
    "\n",
    "\n",
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squard_diff = (t_p - t_c)**2\n",
    "    return squard_diff.mean()\n",
    "\n",
    "\n",
    "w = torch.ones(1)\n",
    "b = torch.zeros(1)\n",
    "\n",
    "t_p = model(t_u, w, b)\n",
    "print(t_p)\n",
    "\n",
    "\n",
    "loss= loss_fn(t_p, t_c)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "\n",
    "delta = 0.1\n",
    "\n",
    "loss_rate_of_change_w = (loss_fn(model(t_u, w + delta,b), t_c)  - loss_fn(model(t_u,w - delta, b), t_c)) / (2.0 * delta)\n",
    "\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w = w - learning_rate * loss_rate_of_change_w\n",
    "\n",
    "loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_c)  - \n",
    "                         loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n",
    "\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6799, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSELoss functions\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "input = torch.randn(10,5, requires_grad=True)\n",
    "target = torch.randn(10, 5)\n",
    "\n",
    "output = loss(input, target)\n",
    "\n",
    "output.backward()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#use of torch.no_grad in pytorch \n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "print(x.requires_grad)\n",
    "\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5]) (20, 5, 1) 62404224\n",
      "torch.Size([4, 5, 3]) (5, 1, 20) 62404224\n",
      "torch.Size([4, 5, 3]) (15, 3, 1) 62386624\n",
      "torch.Size([3, 4, 5]) (20, 5, 1) 62404224\n"
     ]
    }
   ],
   "source": [
    "# Use stride and size to track the memory layout:\n",
    "\n",
    "a = torch.randn(3, 4, 5)\n",
    "b = a.permute(1, 2, 0)\n",
    "c = b.contiguous()\n",
    "d = a.contiguous()\n",
    "# a has \"standard layout\" (also known as C layout in numpy) descending strides, and no memory gaps (stride(i-1) == size(i)*stride(i))\n",
    "print (a.shape, a.stride(), a.data_ptr())\n",
    "# b has same storage as a (data_ptr), but has the strides and sizes swapped around\n",
    "print (b.shape, b.stride(), b.data_ptr())\n",
    "# c is in new storage, where it has been arranged in standard layout (which is \"contiguous\")\n",
    "print (c.shape, c.stride(), c.data_ptr())\n",
    "# d is exactly as a, as a was contiguous all along\n",
    "print (d.shape, d.stride(), d.data_ptr())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
