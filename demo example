
ex: 

099396f3224433e51d27	why do we choose to tolerate things rather than follow our own feelings 	0
21aeec3f8e01c60ba22b	what do you think about the giant petrified trees conspiracy 	0



===============================================================================================================================

# print('Tokenize texts...')


train_dataset.tokens[0] 


['why', 'do', 'we', 'choose', 'to', 'tolerate', 'things', 'rather', 'than', 'follow', 'our', 'own', 'feelings']


train_dataset.tokens[1] 

['what', 'do', 'you', 'think', 'about', 'the', 'giant', 'petrified', 'trees', 'conspiracy']


print(train_dataset.tokens)

[list(['why', 'do', 'we', 'choose', 'to', 'tolerate', 'things', 'rather', 'than', 'follow', 'our', 'own', 'feelings']), list(['what', 'do', 'you', 'think', 'about', 'the', 'giant', 'petrified', 'trees', 'conspiracy'])]



print(submit_dataset.tokens)

[list(['why', 'do', 'zainichi', 'koreans', '在日朝鮮人／韓国人', 'dislike', 'anton', 'antenorcruz']), list(['does', 'delhi', 'university', 'ask', 'questions', 'from', 'general', 'aptitude', 'subjects', 'like', 'general', 'science', 'maths', 'english', 'in', 'the', 



[array([list(['why', 'do', 'we', 'choose', 'to', 'tolerate', 'things', 'rather', 'than', 'follow', 'our', 'own', 'feelings']),
       list(['what', 'do', 'you', 'think', 'about', 'the', 'giant', 'petrified', 'trees', 'conspiracy'])],
      dtype=object), array([], dtype=object), array([list(['why', 'do', 'zainichi', 'koreans', '在日朝鮮人／韓国人', 'dislike', 'anton', 'antenorcruz']),
       list(['does', 'delhi', 'university', 'ask', 'questions', 'from', 'general', 'aptitude', 'subjects', 'like', 'general', 'science', 'maths', 'english', 'in', 'the', 'm', 'a', 'entrance', 'examination'])],
      dtype=object)]


===============================================================================================================================

print('Build vocabulary...')
vocab = preprocessor.build_vocab(datasets, config)

vocab

Counter({'do': 3, 'the': 2, 'why': 2, 'giant': 1, 'subjects': 1, 'choose': 1, 'than': 1, 'zainichi': 1, 'anton': 1, 'we': 1, 'examination': 1, 'questions': 1, 'dislike': 1, 'university': 1, 'rather': 1, 'in': 1, 'tolerate': 1, 'a': 1, 'does': 1, 'feelings': 1, 'our': 1, 'conspiracy': 1, 'what': 1, 'ask': 1, 'own': 1, '在日朝鮮人／韓国人': 1, 'you': 1, 'to': 1, 'm': 1, 'koreans': 1, 'maths': 1, 'general': 1, 'about': 1, 'trees': 1, 'think': 1, 'follow': 1, 'from': 1, 'antenorcruz': 1, 'things': 1, 'like': 1, 'delhi': 1, 'science': 1, 'english': 1, 'aptitude': 1, 'entrance': 1, 'petrified': 1})


self.word_freq

{'giant': 1, 'subjects': 1, 'choose': 1, 'than': 1, 'zainichi': 1, 'anton': 1, 'we': 1, 'examination': 1, 'questions': 1, 'university': 1, 'rather': 1, 'in': 1, 'tolerate': 1, 'delhi': 1, 'does': 1, 'feelings': 1, 'science': 1, 'conspiracy': 1, 'what': 1, 'ask': 1, 'own': 1, 'follow': 1, '在日朝鮮人／韓国人': 1, 'you': 1, 'english': 1, 'the': 2, 'to': 1, 'm': 1, 'koreans': 1, 'maths': 1, 'general': 1, 'about': 1, 'trees': 1, 'think': 1, 'dislike': 1, 'antenorcruz': 1, 'from': 1, 'why': 2, 'things': 1, 'like': 1, 'a': 1, 'our': 1, 'do': 3, '<PAD>': 0, 'aptitude': 1, 'entrance': 1, 'petrified': 1}


self.token2id

{'giant': 1, 'dislike': 10, 'choose': 3, 'than': 4, 'zainichi': 5, 'anton': 6, 'we': 7, 'examination': 8, 'questions': 9, 'university': 11, 'rather': 12, 'in': 13, 'tolerate': 14, 'delhi': 40, 'does': 16, 'feelings': 17, 'science': 41, 'conspiracy': 19, 'what': 20, 'ask': 21, 'own': 22, 'follow': 34, '在日朝鮮人／韓国人': 23, 'you': 24, 'english': 43, 'the': 25, 'to': 26, 'm': 27, 'koreans': 28, 'maths': 29, 'general': 30, 'about': 31, 'trees': 32, 'think': 33, 'subjects': 2, 'antenorcruz': 36, 'from': 35, 'why': 37, 'entrance': 38, 'like': 39, 'a': 15, 'our': 18, 'do': 42, '<PAD>': 0, 'aptitude': 44, 'things': 45, 'petrified': 46}

================================================================================================
================================================

********** print('Build token ids...') it's basically arrange "sentance with token-id"

print(tokenids)

[array([[37, 42,  7,  3, 26, 14, 45, 12,  4, 34, 18, 22, 17,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0],
       [20, 42, 24, 33, 31, 25,  1, 46, 32, 19,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32), array([], shape=(0, 72), dtype=int32), array([[37, 42,  5, 28, 23, 10,  6, 36,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0],
       [16, 40, 11, 21,  9, 35, 30, 44,  2, 39, 30, 41, 29, 43, 13, 25,
        27, 15, 38,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)]


================================================================================================
================================================

ApplyNdArray accept function same as return function  .

======================================================================



*************** print('Build sentence extra features...')

n_dims = 0 


*******************  preprocessor.build_sentence_features


train_dataset._X2 it's basically retun [] - ndarray(2, 0)


********[d.build(config.device) for d in datasets]

in def build(self, device)

self.X tensor
============


tensor([[37, 42,  7,  3, 26, 14, 45, 12,  4, 34, 18, 22, 17,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [20, 42, 24, 33, 31, 25,  1, 46, 32, 19,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])


tensor([[37, 42,  5, 28, 23, 10,  6, 36,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [16, 40, 11, 21,  9, 35, 30, 44,  2, 39, 30, 41, 29, 43, 13, 25, 27, 15,
         38,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])


===================================================================================================


****************print('Load pretrained vectors...')


freqs = np.zeros((len(token2id)), dtype='f')  (47 array build)

ex ::: [0.0.0.0............] (47 array build)

len(token2id) :: 47 (our total Build vocabulary)

embed_shape : (47, 300) 

vectors = np.zeros(embed_shape, dtype='f')  (47 rows , 300 column)


while iterating one by one our golve embedding and check with exitsing our vocab / tokenids if match then set 
"1" in freqs array 

example ::  freqs[token2id[token]] += 1


while iterating one by one our golve embedding and check with exitsing our vocab / tokenids if match then set 
full vector in vectors(same tokenids ex:::: token2id[token] )


example :::

o = "the 1 2 3 4 5 ...300" ----- is len(301)

token, *vector = o.split(' ')

token value is :: the

vector value is :: [1,2,3,4,5....300] that formar is basically list so need to convert into numpy array for shape 

ex .. :  np.array(vector, 'f')
we can check np.array(vector, 'f').shape is  (300)

then assign vector to vectors 

vectors[token2id[token]] += np.array(vector, 'f')

- vectors[freqs != 0] /= freqs[freqs != 0][:, None] 

select value from numpy array (freqs) based on condition is not equals 0  . than change shape example 

freqs[freqs != 0][:, None] - same as "numpy.vstack(freqs[freqs != 0])" 

#one = vectors[freqs != 0]
vectors[freqs != 0] /= freqs[freqs != 0][:, None]
#two = vectors[freqs != 0]
#result = one == two
#print("after::::", result.all())  # so basically we can see there is no any change is there between one to two vector  


#KeyedVectors gensim - models keyvectors

class Word2VecKeyedVectors :::::::
 |  Mapping between words and vectors for the :class:`~gensim.models.Word2Vec` model.
 |  Used to perform operations on the vectors such as vector lookup, distance, similarity etc.


vec = KeyedVectors(300)
add(entities, weights, replace=False) method of gensim.models.keyedvectors.Word2VecKeyedVectors instance


Parameters
----------
entities : list of str
    Entities specified by string ids.
weights: {list of numpy.ndarray, numpy.ndarray}
    List of 1D np.array vectors or a 2D np.array of vectors.
replace: bool, optional
    Flag indicating whether to replace vectors for entities which already exist in the vocabulary,
    if True - replace vectors, otherwise - keep old vectors.



*******************print('Build word embedding matrix...')


example 
import numpy as np
a1 = np.array([1,2,3])
a2 = np.array([4,5,6])
np.stack(a1,a2)
output :: 

array([[1, 2, 3],
       [4, 5, 6]])

np.stack((a1,a2)).mean(axis=0)
output :: array([2.5, 3.5, 4.5])


a3 = np.array([7,8,0])
r1 = np.stack((a1,a2,a3))

(r1 == 0).all(axis=0)
(r1 == 0).all(axis=1)

false to true ==> true to false

it's is basically tilde sign = ~(r1==0).all(axis=1)












